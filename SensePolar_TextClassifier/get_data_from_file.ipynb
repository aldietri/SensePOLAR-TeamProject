{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83e40940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from bertFuncs import analyzeWord, getBert\n",
    "from createDims import createPolarDimension\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "import ast\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file='data_file.xlsx'\n",
    "create_lookup_from_data_file(file,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b265e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb8dc255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_examples_files('word1',ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23011993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples_files(antonym,dictionary):\n",
    "    \n",
    "    examples=dictionary[antonym].split(\"###\")\n",
    "    #save only examples that containt the required word\n",
    "    correct_examples=[]\n",
    "    for example in examples:\n",
    "        if re.search(r'\\b'+text_lowercase(str(antonym))+'\\\\b', text_lowercase(example), re.I) is not None:\n",
    "            correct_examples.append(text_lowercase(remove_whitespace(example)))\n",
    "    \n",
    "\n",
    "    \n",
    "    examples = [sent.translate(str.maketrans({k: \" \" for k in string.punctuation})) for sent in correct_examples]\n",
    "    # add a space after each sentence\n",
    "    return ['{} '.format(sent) for sent in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c857eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_files_fromFile(antonyms_first, out_path,definitions,examples):\n",
    "    \n",
    "    antonyms = [pair for pair in antonyms_first if min(len(get_examples_files(pair[0],examples)),\n",
    "                                                       len(get_examples_files(pair[1],examples))) != 0]\n",
    "    \n",
    "\n",
    "    if len(np.unique(antonyms, axis=0)) != len(antonyms):\n",
    "        print(\"Your antonym list contains duplicates. Please try again!\")\n",
    "        return\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "            \n",
    "    \n",
    "    # get all word sense definitions\n",
    "    synset_defs = [[definitions[anto] for anto in pair] for pair in antonyms]\n",
    "    # get example sentences from dicitionary\n",
    "    examples_readable = {str(pair):{str(anto): get_examples_files(anto,examples) for anto in pair} for pair in antonyms}\n",
    "    examples_lookup = [[[str(anto), get_examples_files(anto,examples)] for anto in pair] for pair in antonyms]\n",
    "    \n",
    "    # save \n",
    "    with open(out_path + 'lookup_synset_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(antonyms, indent=4))\n",
    "    with open(out_path + 'lookup_synset_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(antonyms, p)\n",
    "    with open(out_path + 'lookup_synset_definition.txt', 'w') as t:\n",
    "        t.write(json.dumps(synset_defs, indent=4))  \n",
    "    with open(out_path + 'lookup_synset_definition.pkl', 'wb') as p:\n",
    "        pickle.dump(synset_defs, p)        \n",
    "    with open(out_path + 'antonym_wordnet_example_sentences_readable_extended.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_readable, indent=4))  \n",
    "    with open(out_path + 'lookup_anto_example_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_lookup, indent=4))      \n",
    "    with open(out_path + 'lookup_anto_example_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(examples_lookup, p)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_files_fromFile(antonyms_first, out_path,definitions,examples):\n",
    "    \n",
    "    antonyms = [pair for pair in antonyms_first if min(len(get_examples_files(pair[0],examples)),\n",
    "                                                       len(get_examples_files(pair[1],examples))) != 0]\n",
    "    \n",
    "\n",
    "    if len(np.unique(antonyms, axis=0)) != len(antonyms):\n",
    "        print(\"Your antonym list contains duplicates. Please try again!\")\n",
    "        return\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "            \n",
    "    \n",
    "    # get all word sense definitions\n",
    "    synset_defs = [[definitions[anto] for anto in pair] for pair in antonyms]\n",
    "    # get example sentences from dicitionary\n",
    "    examples_readable = {str(pair):{str(anto): get_examples_files(anto,examples) for anto in pair} for pair in antonyms}\n",
    "    examples_lookup = [[[str(anto), get_examples_files(anto,examples)] for anto in pair] for pair in antonyms]\n",
    "    \n",
    "    # save \n",
    "    with open(out_path + 'lookup_synset_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(antonyms, indent=4))\n",
    "    with open(out_path + 'lookup_synset_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(antonyms, p)\n",
    "    with open(out_path + 'lookup_synset_definition.txt', 'w') as t:\n",
    "        t.write(json.dumps(synset_defs, indent=4))  \n",
    "    with open(out_path + 'lookup_synset_definition.pkl', 'wb') as p:\n",
    "        pickle.dump(synset_defs, p)        \n",
    "    with open(out_path + 'antonym_wordnet_example_sentences_readable_extended.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_readable, indent=4))  \n",
    "    with open(out_path + 'lookup_anto_example_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_lookup, indent=4))      \n",
    "    with open(out_path + 'lookup_anto_example_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(examples_lookup, p)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9942d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_from_data_file(file_name,out_path):\n",
    "    file=r'{}'.format(file_name)\n",
    "    data = pd.read_excel(file)\n",
    "    dimensions=[]\n",
    "    ant_example_dict=defaultdict()\n",
    "    definition_dict=defaultdict()\n",
    "    for index,value in enumerate(data.iloc[:,0]):\n",
    "        \n",
    "        dimensions.append(list([value,data.iloc[:,1][index]]))\n",
    "        #definition_dict[value]=data.iloc[:,4][index]\n",
    "        definition_dict[value]=\" \"\n",
    "        #definition_dict[data.iloc[:,1][index]]=data.iloc[:,5][index]\n",
    "        definition_dict[data.iloc[:,1][index]]=\" \"\n",
    "        ant_example_dict[value]=data.iloc[:,2][index]\n",
    "        ant_example_dict[data.iloc[:,1][index]]=data.iloc[:,3][index]\n",
    "    \n",
    "    create_lookup_files_fromFile(dimensions,out_path,definition_dict,ant_example_dict)\n",
    "    \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b6adfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "out='antonyms_file/' #folder where the lookup files will be saved\n",
    "file='data_file.xlsx'\n",
    "create_lookup_from_data_file(file,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6f2d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['test', 'test2'],\n",
       " ['one', 'two'],\n",
       " ['word1', 'word2'],\n",
       " ['value_test', 'valueq']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "470c1898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "452a290e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'test': 'test is first example. Second sentence example of test. Example without the word.',\n",
       "             'test2': 'test2 is first example. Second sentence example of test2.Example without the word.',\n",
       "             'one': 'example for one.one example sentence.',\n",
       "             'two': 'example for two.two example sentence.',\n",
       "             'word1': 'wrd1 example. eXample of w.',\n",
       "             'word2': 'Word2 is an word for testing.',\n",
       "             'value_test': 'value_test',\n",
       "             'valueq': ''})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e05110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "antonyms = [pair for pair in dim if min(len(get_examples_files(examples[pair[0]],examples)),\n",
    "                                                       len(get_examples_files(examples[pair[1]],examples))) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca948f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995cc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5bbc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookupFiles_out_of_adjectives_list_using_file(file,out_path):\n",
    "    file=r'{}'.format(file)\n",
    "    adjectives = pd.read_excel(file,header=None)\n",
    "    \n",
    "    adjectives=list(adjectives[0])\n",
    "    adjectives\n",
    "    from collections import defaultdict\n",
    "    adj_ant_pairs=[]\n",
    "    d=[]\n",
    "    sorted_d=[]\n",
    "    for word in adjectives:\n",
    "        antonyms=defaultdict()\n",
    "\n",
    "        synsets=wn.synsets(word)\n",
    "         #create dictionary only with synsets that have an antonym\n",
    "        for i in synsets:\n",
    "            if(len(i.lemmas()[0].antonyms()) !=0):\n",
    "                ant=i.lemmas()[0].antonyms()[0]\n",
    "                antonyms[i]=ant.synset()\n",
    "        #keep only antonym pairs that have examples\n",
    "        for key in list(antonyms.keys()):\n",
    "            if (len(key.examples())==0 or len(antonyms[key].examples())==0):\n",
    "                del antonyms[key]\n",
    "        if len(list(antonyms.keys())) !=0:\n",
    "         #append the list of dimmensions\n",
    "            for key in list(antonyms.keys()):\n",
    "                d.append(sorted(list([key.name(),antonyms[key].name()])))\n",
    "\n",
    "    #remove duplicates\n",
    "    df=pd.DataFrame(d)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.reset_index(inplace=True)        \n",
    "    dims=[]\n",
    "    for index, value in enumerate(df[0]):\n",
    "        dims.append(list([value,df[1][index]]))\n",
    "        \n",
    "        \n",
    "    dimensions=dims\n",
    "    ant_example_dict=defaultdict()\n",
    "    definition_dict=defaultdict()\n",
    "    for index,value in enumerate(dimensions):\n",
    " \n",
    "\n",
    "        definition_dict[value[0]]=wn.synset(value[1]).definition()\n",
    "        definition_dict[value[1]]=wn.synset(value[0]).definition()\n",
    "        ant_example_dict[value[0]]='.'.join(str(x) for x in wn.synset(value[0]).examples())\n",
    "        ant_example_dict[value[1]]='.'.join(str(x) for x in wn.synset(value[1]).examples())\n",
    "        \n",
    "\n",
    "\n",
    "    return ant_example_dict,dimensions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74705129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e79f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='adjectives_list.xlsx'\n",
    "dictionary,dims=create_lookupFiles_out_of_adjectives_list_using_file(file_name,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0140024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['evil.n.03', 'good.n.02'],\n",
       " ['bad.n.01', 'good.n.03'],\n",
       " ['bad.a.01', 'good.a.01'],\n",
       " ['ill.r.01', 'well.r.01'],\n",
       " ['regretful.a.01', 'unregretful.a.01'],\n",
       " ['cold.a.01', 'hot.a.01'],\n",
       " ['cold.a.02', 'hot.a.03'],\n",
       " ['beautiful.a.01', 'ugly.a.01'],\n",
       " ['common.a.01', 'individual.a.01'],\n",
       " ['common.a.02', 'uncommon.a.01']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c74bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_examples_files('bad.a.01',dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bf4a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['bad']='.'.join(str(x) for x in wn.synset('bad.a.01').examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36d3353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    antonym='bad'\n",
    "    examples=dictionary[antonym].split(\".\")\n",
    "    #try:\n",
    "     #   antonym=antonym.split('.')[0]\n",
    "    #except:\n",
    "     #   antonym=antonym\n",
    "    #save only examples that containt the required word\n",
    "    correct_examples=[]\n",
    "    for example in examples:\n",
    "        if re.search(r'\\b'+text_lowercase(str(antonym.split('.')[0]))+'\\\\b', text_lowercase(example), re.I) is not None:\n",
    "            correct_examples.append(text_lowercase(remove_whitespace(example)))\n",
    "    \n",
    "\n",
    "    \n",
    "    examples = [sent.translate(str.maketrans({k: \" \" for k in string.punctuation})) for sent in correct_examples]\n",
    "    # add a space after each sentence\n",
    "    x=['{} '.format(sent) for sent in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0c705c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mantonym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "antonym.split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12bd6dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'evil.n.03': 'attempts to explain the origin of evil in the world',\n",
       "             'good.n.02': 'there is much good to be found in people',\n",
       "             'bad.n.01': 'take the bad with the good',\n",
       "             'good.n.03': 'weigh the good against the bad.among the highest goods of all are happiness and self-realization',\n",
       "             'bad.a.01': 'a bad report card.his sloppy appearance made a bad impression.a bad little boy.clothes in bad shape.a bad cut.bad luck.the news was very bad.the reviews were bad.the pay is bad.it was a bad light for reading.the movie was a bad choice',\n",
       "             'good.a.01': 'good news from the hospital.a good report card.when she was good she was very very good.a good knife is one good for cutting.this stump will make a good picnic table.a good check.a good joke.a good exterior paint.a good secretary.a good dress for the office',\n",
       "             'ill.r.01': 'he was ill prepared.it ill befits a man to betray old friends.the car runs badly.he performed badly on the exam.the team played poorly.ill-fitting clothes.an ill-conceived plan',\n",
       "             'well.r.01': 'the children behaved well.a task well done.the party went well.he slept well.a well-argued thesis.a well-seasoned dish.a well-planned party.the baby can walk pretty good',\n",
       "             'regretful.a.01': 'felt regretful over his vanished youth.regretful over mistakes she had made.he felt bad about breaking the vase',\n",
       "             'unregretful.a.01': 'was completely unregretful about what had happened',\n",
       "             'cold.a.01': 'a cold climate.a cold room.dinner has gotten cold.cold fingers.if you are cold, turn up the heat.a cold beer',\n",
       "             'hot.a.01': \"hot stove.hot water.a hot August day.a hot stuffy room.she's hot and tired.a hot forehead\",\n",
       "             'cold.a.02': 'a cold unfriendly nod.a cold and unaffectionate person.a cold impersonal manner.cold logic.the concert left me cold',\n",
       "             'hot.a.03': 'a hot temper.a hot topic.a hot new book.a hot love affair.a hot argument',\n",
       "             'beautiful.a.01': 'a beautiful child.beautiful country.a beautiful painting.a beautiful theory.a beautiful party',\n",
       "             'ugly.a.01': 'an ugly face.ugly furniture',\n",
       "             'common.a.01': 'for the common good.common lands are set aside for use by all members of a community',\n",
       "             'individual.a.01': 'individual drops of rain.please mark the individual pages.they went their individual ways',\n",
       "             'common.a.02': 'the common man.a common sailor.the common cold.a common nuisance.followed common procedure.it is common knowledge that she lives alone.the common housefly.a common brand of soap',\n",
       "             'uncommon.a.01': \"uncommon birds.frost and floods are uncommon during these months.doing an uncommon amount of business.an uncommon liking for money.he owed his greatest debt to his mother's uncommon character and ability\",\n",
       "             'bad': 'a bad report card.his sloppy appearance made a bad impression.a bad little boy.clothes in bad shape.a bad cut.bad luck.the news was very bad.the reviews were bad.the pay is bad.it was a bad light for reading.the movie was a bad choice'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2cc5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a bad report card', 'his sloppy appearance made a bad impression', 'a bad little boy', 'clothes in bad shape', 'a bad cut', 'bad luck', 'the news was very bad', 'the reviews were bad', 'the pay is bad', 'it was a bad light for reading', 'the movie was a bad choice']\n"
     ]
    }
   ],
   "source": [
    "examples=dictionary['bad.a.01'].split(\".\")\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4361d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
