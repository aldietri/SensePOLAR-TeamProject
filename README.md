[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FJanEnglerRWTH%2FSensePOLAR&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false)](https://hits.seeyoufarm.com)
# SensePOLAR: Interpreting Contextual Word Embeddings with Word Sense Awareness

SensePOLAR is a groundbreaking framework that introduces interpretability into contextual word embeddings, with a focus on word sense awareness. This research, accepted at EMNLP'22 (findings), represents a significant step forward in the quest to make contextual word embeddings, such as BERT, more interpretable and contextually relevant.

## Introduction

Interpretability in word embeddings is a crucial area of research within the field of natural language processing. The ability to understand and explain the meaning of words in different contexts is fundamental for various NLP applications. Recent efforts have explored methods for imbuing word embeddings with interpretability, often by using polar dimensions to rate words on scales that capture various user-selected senses. Examples of such approaches include SemAxis, POLAR, FrameAxis, and BiImp. While these methods have made significant strides in providing interpretable dimensions for words, they face a limitation when it comes to polysemy, i.e., the multiple senses of words.

## Sense Aware Interpretability

To address the challenge of polysemy, SensePOLAR extends the original POLAR framework to offer word-sense aware interpretability for pre-trained contextual word embeddings. This innovation enables interpretable word embeddings that can distinguish between different senses of words. Unlike previous approaches, SensePOLAR considers the context-specific meaning of words, resulting in interpretable dimensions that align well with human judgment.

## Key Features

- **Word Sense Awareness:** SensePOLAR is designed to understand and interpret word embeddings in the context of multiple senses. It rates words on scales associated with opposite senses (e.g., "good"â†”"bad"), providing sense-aware interpretations.

- **Performance:** The interpretable word embeddings generated by SensePOLAR maintain performance levels comparable to original contextual word embeddings across various NLP tasks, including benchmarks like GLUE and SQuAD.

- **Polysemy Handling:** SensePOLAR overcomes the limitation of existing approaches by offering sense-aware interpretations, making it a valuable tool for capturing the nuances of word meanings.

## How SensePOLAR Works

SensePOLAR transforms pre-trained contextual word embeddings into an interpretable space where a word's semantics are rated on scales individually encoded by opposite senses. These dimensions are representative of the strength of the relationship between a word and a dimension, allowing for dimension ranking and identifying the most discriminative dimensions for a word. The sense-aware interpretations generated by SensePOLAR align with human judgment and can distinguish between different contextual meanings of words.

## In This Repository

In this repository, we provide an extended SensePOLAR framework and an interpretability visualization tool that you can experiment with and explore for your research projects. These tools will help you gain a deeper understanding of SensePOLAR's implementation and its practical applications.


# Usage

## Install Requirements
To install the necessary dependencies, run the following command:
Python version : 3.10.10
```
pip install -r requirements.txt
```

## Running the web application
To run the web application, use the following command:
```
streamlit run Introduction.py
```
The intro page has detailed instructions on how to use the application

# Using SensePOLAR framework as a package
```
pip install .
```

* ## Initialize the Word Embeddings Model:
  The SensePOLAR framework supports various word embedding models, including BERT, ALBERT, RoBERTa, and GPT-2. To initialize a specific model, import it and create an instance:
```
from sensepolar.embed.bertEmbed import BERTWordEmbeddings
from sensepolar.embed.gptEmbed import GPT2WordEmbeddings
from sensepolar.embed.robertaEmbed import RoBERTaWordEmbeddings
from sensepolar.embed.albertEmbed import ALBERTWordEmbeddings

model = BERTWordEmbeddings()
```
You can similarly initialize other models for your specific needs.

* ## Initialize the Dictionary

  SensePOLAR supports multiple dictionaries, including WordNet, Wordnik, and DictionaryAPI. To initialize a dictionary, use the following code:
```
from sensepolar.oracle.dictionaryapi import Dictionary

dictionary = Dictionary('wordnet', api_key='')

```
You can choose the dictionary that suits your requirements. Additionally, you can extend the framework to support other languages by updating the model and dictionary accordingly.

* ## Selecting Polars and Creating Polar Dimensions
  You can define antonym pairs and indices to create polar dimensions. Here's an example:
```
out_path = './antonyms/'

antonym_pairs = [['laugh', 'cry'],  ['good', 'bad'], ['happy', 'sad'], ['good', 'bad']]
indices = [[0, 1], [1, 0], [0, 0], [0, 0]]

lookupSpace = LookupCreator(dictionary, out_path, antonym_pairs=antonym_pairs, is_path=False)
lookupSpace.create_lookup_files(indices=indices)

pdc = PolarDimensions(model, antonym_path=out_path + "antonym_wordnet_example_sentences_readable_extended.txt")
pdc.create_polar_dimensions(out_path)

```

* ## Calculate Polar Values
  You can calculate polar values for specific subjects using the following code:
```
words, contexts = ['sun', 'moon'], ['sun rises in the east', 'moon is not so far anymore']
# read_word_context_file('data/word_context.csv')
wp = WordPolarity(model, antonym_path=antonym_path, method='projection')

polar_dimensions = []
for word, context in zip(words, contexts):
    dimension = wp.analyze_word(word, context)
    polar_dimensions.append(dimension)
```

* ## Visualizing Sensepolar Dimensions
  SensePOLAR framework provides visualization tools to explore polar dimensions:
```
plotter = PolarityPlotter(sort_by='descriptive', order_by='asec')

# Plot polar dimensions
plotter.plot_word_polarity(words, contexts, polar_dimensions)
plotter.plot_word_polarity_2d(words, contexts, polar_dimensions)
plotter.plot_word_polarity(words, contexts, polar_dimensions)
plotter.plot_word_polarity_polar_fig(words, contexts, polar_dimensions)
plotter.plot_descriptive_antonym_pairs(words,contexts, polar_dimensions, words, 4)
```

## Downstream Tasks
You can also evaluate the SensePOLAR Embeddings 
*  GLUE Benchmark
*  Polarity Detection
*  Text Classification

Code for this can be found under the folder downstream_tasks


## Literature

- **SensePOLAR Framework:**
  - Jan Engler, Sandipan Sikdar, Marlene Lutz, Markus Strohmaier. "SensePOLAR: Word sense aware interpretability for pre-trained contextual word embeddings." arXiv preprint arXiv:2301.04704 (2023). [Link to Paper](https://arxiv.org/abs/2301.04704)

- **Static POLAR Framework:**
  - Mathew, B., Sikdar, S., Lemmerich, F., & Strohmaier, M. (2020, April). The polar framework: Polar opposites enable interpretability of pre-trained word embeddings. In Proceedings of the Web Conference 2020 (pp. 1548-1558).

- **BERT Model:**
  - Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.

