{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7ed4b4",
   "metadata": {},
   "source": [
    "## Files used in bertFuncs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e420e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alext\\Anaconda3\\envs\\SensePOLAR\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertFuncs import analyzeWord, getBert\n",
    "from createDims import createPolarDimension\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "import ast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a9ed2",
   "metadata": {},
   "source": [
    "## Creating the required lookup files\n",
    "\n",
    "The lookup files are needed to set up the POLAR dimensions and to match these dimensions to word sense definitions and example sentences, when analyzing the result.\n",
    "\n",
    "The function ``create_lookup_files`` takes a list of lists as input. Each inner list contains a polar sense pair, where each word sense must be in WordNet readable format e.g. ``cold.a.01``), in orderder to automatically retrieve definitions and example sentences. All lookup files will be stored in the folder ``lookup_path``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a12d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a975610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('a4c72377-ee1b-42fa-a29a-a35163cc2164')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d8e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_name(antonym):\n",
    "    return wn.synset(antonym).lemma_names()[0]\n",
    "\n",
    "def get_examples(antonym):\n",
    "    examples = wn.synset(antonym).examples()\n",
    "    # replace punctuation symbols with spaces\n",
    "    examples = [sent.translate(str.maketrans({k: \" \" for k in string.punctuation})) for sent in examples]\n",
    "    # add a space after each sentence\n",
    "    return ['{} '.format(sent) for sent in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "958ab34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_files(antonyms, lookup_path):\n",
    "    if len(np.unique(antonyms, axis=0)) != len(antonyms):\n",
    "        print(\"Your antonym list contains duplicates. Please try again!\")\n",
    "        return\n",
    "    \n",
    "    # get all word sense definitions\n",
    "    synset_defs = [[wn.synset(anto).definition() for anto in pair] for pair in antonyms]\n",
    "    # get example sentences from wordnet\n",
    "    examples_readable = {str(pair):{get_name(anto): get_examples(anto) for anto in pair} for pair in antonyms}\n",
    "    examples_lookup = [[[get_name(anto), get_examples(anto)] for anto in pair] for pair in antonyms]\n",
    "    \n",
    "    # save \n",
    "    with open(out_path + 'lookup_synset_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(antonyms, indent=4))\n",
    "    with open(out_path + 'lookup_synset_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(antonyms, p)\n",
    "    with open(lookup_path + 'lookup_synset_definition.txt', 'w') as t:\n",
    "        t.write(json.dumps(synset_defs, indent=4))  \n",
    "    with open(lookup_path + 'lookup_synset_definition.pkl', 'wb') as p:\n",
    "        pickle.dump(synset_defs, p)        \n",
    "    with open(lookup_path + 'antonym_wordnet_example_sentences_readable_extended.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_readable, indent=4))  \n",
    "    with open(lookup_path + 'lookup_anto_example_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_lookup, indent=4))      \n",
    "    with open(lookup_path + 'lookup_anto_example_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(examples_lookup, p)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beac2a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hot.a.01'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"hot\")[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af96f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m definitions \u001b[39m=\u001b[39m [wn\u001b[39m.\u001b[39msynsets(\u001b[39m\"\u001b[39m\u001b[39mtwo\u001b[39m\u001b[39m\"\u001b[39m)[i]\u001b[39m.\u001b[39mdefinition() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)]\n\u001b[0;32m      2\u001b[0m definitions\n",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m definitions \u001b[39m=\u001b[39m [wn\u001b[39m.\u001b[39;49msynsets(\u001b[39m\"\u001b[39;49m\u001b[39mtwo\u001b[39;49m\u001b[39m\"\u001b[39;49m)[i]\u001b[39m.\u001b[39mdefinition() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)]\n\u001b[0;32m      2\u001b[0m definitions\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "definitions = [wn.synsets(\"two\")[i].definition() for i in range(5)]\n",
    "definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2f37b",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e77ad0",
   "metadata": {},
   "source": [
    "Polar dimensions should be __given__ as nested list of antonym pairs in wordnet representation (sense-annotated).\n",
    "\n",
    "_Example:_   \n",
    "`\n",
    "[\n",
    "    ['a_posteriori.a.01', 'a_priori.a.01'],\n",
    "    ['abaxial.a.01', 'adaxial.a.01'],\n",
    "    ['abridge.v.01', 'elaborate.v.01'],\n",
    "    ...\n",
    "]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f200e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder in which all lookup files will be stored\n",
    "out_path = 'antonyms/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89588ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 3 exemplary POLAR dimensions\n",
    "dims = [['cold.a.01', 'hot.a.01'], ['bad.a.01', 'good.a.01'], ['intelligent.a.01', 'unintelligent.a.01'], ['capable.a.01', 'incapable.a.01']]\n",
    "    \n",
    "# create all lookup files\n",
    "create_lookup_files(dims, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f240e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# get the embedding model \n",
    "tokenizer, model = getBert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e2f2c",
   "metadata": {},
   "source": [
    "Create the POLAR matrix (for base change or projection) from a given set of antonyms. The antonyms and their example sentences are forwarded to an embedding model (here: BERT) from which the required embeddings and difference vectors are created. ``antonym_path`` specifies where the readable example sentence lookup file is currently stored. ``out_path`` specifies where the POLAR matrix should be stored.\n",
    "\n",
    "The corresponding function can be found in ``createDims.py`` which is not part of the official SensePOLAR repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a2a4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start forwarding the Polar opposites ...\n"
     ]
    }
   ],
   "source": [
    "# create the base change matrix (this might take some time)\n",
    "createPolarDimension(model, tokenizer, out_path=out_path, antonym_path=out_path + \"antonym_wordnet_example_sentences_readable_extended.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8b9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the word:  school\n",
      "In the context of:  school teaches you a lot of smart things\n",
      "Top:  1\n",
      "Dimension:  capable<------>incapable\n",
      "Definitions:  (usually followed by `of') having capacity or ability<------>(followed by `of') lacking capacity or ability\n",
      "Value: -0.21221492\n",
      "\n",
      "\n",
      "Top:  2\n",
      "Dimension:  bad<------>good\n",
      "Definitions:  having undesirable or negative qualities<------>having desirable or positive qualities especially those suitable for a thing specified\n",
      "Value: -0.15057667\n",
      "\n",
      "\n",
      "Top:  3\n",
      "Dimension:  intelligent<------>unintelligent\n",
      "Definitions:  having the capacity for thought and reason especially to a high degree<------>lacking intelligence\n",
      "Value: -0.1265351\n",
      "\n",
      "\n",
      "Top:  4\n",
      "Dimension:  cold<------>hot\n",
      "Definitions:  having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration<------>used of physical heat; having a high or higher than desirable temperature or giving off heat or feeling or causing a sensation of heat or burning\n",
      "Value:                      0.06429225\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['capable---incapable',\n",
       " 'bad---good',\n",
       " 'intelligent---unintelligent',\n",
       " 'cold---hot']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base change does not work well with only few dimensions -> compare with projection\n",
    "antonym_path = out_path + \"polar_dimensions.pkl\"\n",
    "word = \"school\"\n",
    "context = \"school teaches you a lot of smart things\"\n",
    "analyzeWord(word, context, model=model,tokenizer=tokenizer, antonym_path=antonym_path, lookup_path=out_path, numberPolar=4) #method=\"projection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d81d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the word:  fire\n",
      "In the context of:  the fire is burning\n",
      "Top:  1\n",
      "Dimension:  cold<------>hot\n",
      "Definitions:  having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration<------>used of physical heat; having a high or higher than desirable temperature or giving off heat or feeling or causing a sensation of heat or burning\n",
      "Value:                      3.1664367\n",
      "\n",
      "\n",
      "Top:  2\n",
      "Dimension:  intelligent<------>unintelligent\n",
      "Definitions:  having the capacity for thought and reason especially to a high degree<------>lacking intelligence\n",
      "Value: -1.3334554\n",
      "\n",
      "\n",
      "Top:  3\n",
      "Dimension:  capable<------>incapable\n",
      "Definitions:  (usually followed by `of') having capacity or ability<------>(followed by `of') lacking capacity or ability\n",
      "Value:                      0.23145732\n",
      "\n",
      "\n",
      "Top:  4\n",
      "Dimension:  bad<------>good\n",
      "Definitions:  having undesirable or negative qualities<------>having desirable or positive qualities especially those suitable for a thing specified\n",
      "Value: -0.16076803\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cold---hot',\n",
       " 'intelligent---unintelligent',\n",
       " 'capable---incapable',\n",
       " 'bad---good']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antonym_path = out_path + \"polar_dimensions.pkl\"\n",
    "word = \"fire\"\n",
    "context = \"the fire is burning\"\n",
    "\n",
    "analyzeWord(word, context, model=model, tokenizer=tokenizer, antonym_path=antonym_path, lookup_path=out_path, numberPolar=4, method=\"projection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
